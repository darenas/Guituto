{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple example for using a premade tf.estimator\n",
    "\n",
    "In this notebook we cover the creation of a couple premade estimators and using them for a prediction problem. \n",
    "\n",
    "Note: The contents of this notebook are inspired on [the GCP tutorials](https://github.com/GoogleCloudPlatform/training-data-analyst) and the [Tensorflow](https://www.tensorflow.org/) documentation. (Kudos to the authors!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was tested with the Tensorflow version: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "#First of all, some imports and general stuff (old C/C++ habits)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from sodapy import Socrata  # pip install sodapy\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "OUTPUT_BASE_DIR = '../outputs/Simple-TF.estimator-example'\n",
    "DATASET_DIR = '../datasets'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "print(\"This notebook was tested with the Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators\n",
    "Lets start by quickly reviewing the concept of Tensorflow's Estimator API. The Estimator API provides methods to train ML models, to judge the model's accuracy, and to generate predictions. An Estimator is TensorFlow's high-level representation of a complete model. A premade Estimator is one of the common Estimators, a Linear Regressor for instance, that are provided by Tensorflow for out-of-the-box use.<br>\n",
    "To write a TensorFlow program based on pre-made Estimators, on should:<br>\n",
    "**(1)** Define the model's feature columns.<br>\n",
    "**(2)** Create the input function(s).<br>\n",
    "**(3)** Instantiate an Estimator, specifying the feature columns and various hyperparameters.<br>\n",
    "**(4)** Use the Estimator (training, evaluation, prediction).<br>\n",
    "This notebook cover these for points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "Before starting with the first step, lets just quickly review the dataset used for this exampe: the [TLC taxi dataset](https://data.cityofnewyork.us/Transportation/TLC-Taxi-Data/gkne-dk5s). This dataset contains information about taxi rides in NYC such as pickup location, number of passengers and fare amount.<br>\n",
    "We are going to download this data directly from the official site. **Important:** Consider to download the dataset only ONCE. To do this set the *downloadData* variable to True for a single execution of the following cell. This is to avoid downloading multiple times the same data which will unnecessarly overload the server. Note that the full dataset contains over 156M rows (Sept-18) but we are downloading there only the first 200K entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadData = False\n",
    "\n",
    "if downloadData:\n",
    "    # Example authenticated client (needed for non-public datasets):\n",
    "    # client = Socrata(data.cityofnewyork.us,\n",
    "    #                  MyAppToken,\n",
    "    #                  userame=\"user@example.com\",\n",
    "    #                  password=\"AFakePassword\")\n",
    "\n",
    "    # Unauthenticated client only works with public data sets. Note 'None'\n",
    "    # in place of application token, and no username or password:\n",
    "    client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "    \n",
    "    results = client.get(\"gkne-dk5s\", limit=200000) # returned as JSON from API/converted to Python list of dictionaries by sodapy\n",
    "    ##results_df = pd.DataFrame.from_records(results) # if we were to use directly without saving a local copy\n",
    "    with open(os.path.join(DATASET_DIR, 'taxi-temp.json'), 'w') as outfile:\n",
    "        json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the data to see what it contains. A pretty straightforward way of reading data is to load it from the source, e.g., a .csv file, into an internal representation, e.g., a panda.dataframe. Keep in mind that sufficient memory is required as the entire contents of the file are loaded at once, in this cas it should be ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_json('../datasets/taxi-temp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see some of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>imp_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>vendor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-26T17:34:00.000</td>\n",
       "      <td>40.767107</td>\n",
       "      <td>-73.982538</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>CSH</td>\n",
       "      <td>2014-02-26T17:28:00.000</td>\n",
       "      <td>40.757502</td>\n",
       "      <td>-73.973135</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.07</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-15T10:08:00.000</td>\n",
       "      <td>40.739422</td>\n",
       "      <td>-73.978727</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>CSH</td>\n",
       "      <td>2014-02-15T10:01:00.000</td>\n",
       "      <td>40.747350</td>\n",
       "      <td>-73.986125</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-06T05:03:10.000</td>\n",
       "      <td>40.648633</td>\n",
       "      <td>-73.781826</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>CRD</td>\n",
       "      <td>2014-12-06T04:42:16.000</td>\n",
       "      <td>40.754909</td>\n",
       "      <td>-73.971853</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.33</td>\n",
       "      <td>69.38</td>\n",
       "      <td>16.70</td>\n",
       "      <td>CMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-23T01:17:00.000</td>\n",
       "      <td>40.673935</td>\n",
       "      <td>-73.964673</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>CSH</td>\n",
       "      <td>2014-01-23T01:08:00.000</td>\n",
       "      <td>40.683642</td>\n",
       "      <td>-73.977057</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-31T08:33:00.000</td>\n",
       "      <td>40.789920</td>\n",
       "      <td>-73.952352</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>CRD</td>\n",
       "      <td>2014-01-31T08:13:00.000</td>\n",
       "      <td>40.738062</td>\n",
       "      <td>-73.983817</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dropoff_datetime  dropoff_latitude  dropoff_longitude  fare_amount  \\\n",
       "0  2014-02-26T17:34:00.000         40.767107         -73.982538          6.0   \n",
       "1  2014-02-15T10:08:00.000         40.739422         -73.978727          6.5   \n",
       "2  2014-12-06T05:03:10.000         40.648633         -73.781826         52.0   \n",
       "3  2014-01-23T01:17:00.000         40.673935         -73.964673          8.5   \n",
       "4  2014-01-31T08:33:00.000         40.789920         -73.952352         17.0   \n",
       "\n",
       "   imp_surcharge  mta_tax  passenger_count payment_type  \\\n",
       "0            1.0      0.5                2          CSH   \n",
       "1            0.0      0.5                2          CSH   \n",
       "2            0.0      0.5                1          CRD   \n",
       "3            0.5      0.5                1          CSH   \n",
       "4            0.0      0.5                1          CRD   \n",
       "\n",
       "           pickup_datetime  pickup_latitude  pickup_longitude  rate_code  \\\n",
       "0  2014-02-26T17:28:00.000        40.757502        -73.973135          1   \n",
       "1  2014-02-15T10:01:00.000        40.747350        -73.986125          1   \n",
       "2  2014-12-06T04:42:16.000        40.754909        -73.971853          2   \n",
       "3  2014-01-23T01:08:00.000        40.683642        -73.977057          1   \n",
       "4  2014-01-31T08:13:00.000        40.738062        -73.983817          1   \n",
       "\n",
       "  store_and_fwd_flag  tip_amount  tolls_amount  total_amount  trip_distance  \\\n",
       "0                NaN        0.00          0.00          7.50           1.07   \n",
       "1                NaN        0.00          0.00          7.00           0.92   \n",
       "2                  N       11.55          5.33         69.38          16.70   \n",
       "3                NaN        0.00          0.00          9.50           1.85   \n",
       "4                NaN        2.50          0.00         20.00           4.26   \n",
       "\n",
       "  vendor_id  \n",
       "0       VTS  \n",
       "1       VTS  \n",
       "2       CMT  \n",
       "3       VTS  \n",
       "4       VTS  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model: \n",
    "The ML model will be specified a little bit later, since we are using premade estimators, we will be able to choose among some different available options, idelly selecting the best match for our problem: the simplest model capable of adequately fitting our dataset. Keep in mind that *simplicity is the ultimate sophistication* or *the KISS principle*, depending on your preferences :)<br>\n",
    "\n",
    "Two important pars of any ML model are the inputs and the outpus, which are directly related to the problem we are trying to solve. Lets now identify which are the outputs (i.e., the objective of our model) and the inputs (which are the features).\n",
    "### Objective (outputs)\n",
    "The objective of the Estimator that we will use in this example is to predict the fare amount of a cab ride (*fare_amount* coumn). This defines already the type of problem we are trying to solve here: a regression problem (the output is a single continuous value). The corresponding column becomes the objective.\n",
    "### Features (inputs)\n",
    "All the other columns can be directly used as inputs of the model (features). However, we are not going to do this because not all columns have an impact on (or are availible when) predicting the fare amount (e.g., the payement type). Moreover, the objective of this notebook is to show a simple way of implementing an estimator, not to produce a performant model. So lets drop out some columns and then show some statistics of the dataset, which is always a good place to start for understanding the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.932246</td>\n",
       "      <td>-72.490769</td>\n",
       "      <td>12.651451</td>\n",
       "      <td>39.937156</td>\n",
       "      <td>-72.501230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.734806</td>\n",
       "      <td>10.374468</td>\n",
       "      <td>10.448343</td>\n",
       "      <td>5.716558</td>\n",
       "      <td>10.341616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-180.000000</td>\n",
       "      <td>-180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-180.000000</td>\n",
       "      <td>-180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.733340</td>\n",
       "      <td>-73.991407</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>40.734567</td>\n",
       "      <td>-73.992190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.752772</td>\n",
       "      <td>-73.979950</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>40.752372</td>\n",
       "      <td>-73.981875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.767867</td>\n",
       "      <td>-73.962980</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>40.766825</td>\n",
       "      <td>-73.966936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.341914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>358.210000</td>\n",
       "      <td>45.341914</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dropoff_latitude  dropoff_longitude    fare_amount  pickup_latitude  \\\n",
       "count     200000.000000      200000.000000  200000.000000    200000.000000   \n",
       "mean          39.932246         -72.490769      12.651451        39.937156   \n",
       "std            5.734806          10.374468      10.448343         5.716558   \n",
       "min         -180.000000        -180.000000       0.000000      -180.000000   \n",
       "25%           40.733340         -73.991407       6.500000        40.734567   \n",
       "50%           40.752772         -73.979950       9.500000        40.752372   \n",
       "75%           40.767867         -73.962980      14.500000        40.766825   \n",
       "max           45.341914           0.000000     358.210000        45.341914   \n",
       "\n",
       "       pickup_longitude  \n",
       "count     200000.000000  \n",
       "mean         -72.501230  \n",
       "std           10.341616  \n",
       "min         -180.000000  \n",
       "25%          -73.992190  \n",
       "50%          -73.981875  \n",
       "75%          -73.966936  \n",
       "max            0.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = df_all.drop(columns=['imp_surcharge', 'mta_tax', 'passenger_count', \n",
    "                                'payment_type', 'rate_code', 'store_and_fwd_flag', 'tip_amount', \n",
    "                                'tolls_amount', 'total_amount', 'trip_distance', 'vendor_id'])\n",
    "col_names = list(df_all.columns.values)\n",
    "\n",
    "label = 'fare_amount'\n",
    "features = col_names\n",
    "features.remove(label)\n",
    "\n",
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The describe method shows some statistics about continuous variables, but what about the *dropoff_datetime* and *pickup_datetime* columns? these seems to be of type datetime, lets output the types of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dropoff_datetime      object\n",
       "dropoff_latitude     float64\n",
       "dropoff_longitude    float64\n",
       "fare_amount          float64\n",
       "pickup_datetime       object\n",
       "pickup_latitude      float64\n",
       "pickup_longitude     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns are classed as *obejct*, in fact the particular format is not even recognized as DateTime standard format. Lets cast these columns into float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropoff_datetime     float64\n",
      "dropoff_latitude     float64\n",
      "dropoff_longitude    float64\n",
      "fare_amount          float64\n",
      "pickup_datetime      float64\n",
      "pickup_latitude      float64\n",
      "pickup_longitude     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.404001e+09</td>\n",
       "      <td>39.932246</td>\n",
       "      <td>-72.490769</td>\n",
       "      <td>12.651451</td>\n",
       "      <td>1.404000e+09</td>\n",
       "      <td>39.937156</td>\n",
       "      <td>-72.501230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.068242e+06</td>\n",
       "      <td>5.734806</td>\n",
       "      <td>10.374468</td>\n",
       "      <td>10.448343</td>\n",
       "      <td>9.068208e+06</td>\n",
       "      <td>5.716558</td>\n",
       "      <td>10.341616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.388532e+09</td>\n",
       "      <td>-180.000000</td>\n",
       "      <td>-180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.388531e+09</td>\n",
       "      <td>-180.000000</td>\n",
       "      <td>-180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.396106e+09</td>\n",
       "      <td>40.733340</td>\n",
       "      <td>-73.991407</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.396105e+09</td>\n",
       "      <td>40.734567</td>\n",
       "      <td>-73.992190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.403608e+09</td>\n",
       "      <td>40.752772</td>\n",
       "      <td>-73.979950</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>1.403607e+09</td>\n",
       "      <td>40.752372</td>\n",
       "      <td>-73.981875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.411993e+09</td>\n",
       "      <td>40.767867</td>\n",
       "      <td>-73.962980</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>1.411992e+09</td>\n",
       "      <td>40.766825</td>\n",
       "      <td>-73.966936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.420067e+09</td>\n",
       "      <td>45.341914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>358.210000</td>\n",
       "      <td>1.420067e+09</td>\n",
       "      <td>45.341914</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dropoff_datetime  dropoff_latitude  dropoff_longitude    fare_amount  \\\n",
       "count      2.000000e+05     200000.000000      200000.000000  200000.000000   \n",
       "mean       1.404001e+09         39.932246         -72.490769      12.651451   \n",
       "std        9.068242e+06          5.734806          10.374468      10.448343   \n",
       "min        1.388532e+09       -180.000000        -180.000000       0.000000   \n",
       "25%        1.396106e+09         40.733340         -73.991407       6.500000   \n",
       "50%        1.403608e+09         40.752772         -73.979950       9.500000   \n",
       "75%        1.411993e+09         40.767867         -73.962980      14.500000   \n",
       "max        1.420067e+09         45.341914           0.000000     358.210000   \n",
       "\n",
       "       pickup_datetime  pickup_latitude  pickup_longitude  \n",
       "count     2.000000e+05    200000.000000     200000.000000  \n",
       "mean      1.404000e+09        39.937156        -72.501230  \n",
       "std       9.068208e+06         5.716558         10.341616  \n",
       "min       1.388531e+09      -180.000000       -180.000000  \n",
       "25%       1.396105e+09        40.734567        -73.992190  \n",
       "50%       1.403607e+09        40.752372        -73.981875  \n",
       "75%       1.411992e+09        40.766825        -73.966936  \n",
       "max       1.420067e+09        45.341914          0.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[['pickup_datetime','dropoff_datetime']] = df_all[['pickup_datetime','dropoff_datetime']].applymap(\n",
    "            lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%f\").timestamp() )\n",
    "print(df_all.dtypes)\n",
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we can now see that values on these transformed columns are huge, this may cause stability problems in our model. Besides it is always better to normalize all inputs (the outputs are not necessarly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.733351e-15</td>\n",
       "      <td>1.345292e-13</td>\n",
       "      <td>-1.373620e-13</td>\n",
       "      <td>12.651451</td>\n",
       "      <td>8.333068e-16</td>\n",
       "      <td>-7.267381e-14</td>\n",
       "      <td>1.308183e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>10.448343</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.705902e+00</td>\n",
       "      <td>-3.835043e+01</td>\n",
       "      <td>-1.036287e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.705888e+00</td>\n",
       "      <td>-3.847370e+01</td>\n",
       "      <td>-1.039477e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.706775e-01</td>\n",
       "      <td>1.396898e-01</td>\n",
       "      <td>-1.446472e-01</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>-8.706638e-01</td>\n",
       "      <td>1.394914e-01</td>\n",
       "      <td>-1.441710e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.335732e-02</td>\n",
       "      <td>1.430782e-01</td>\n",
       "      <td>-1.435428e-01</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>-4.336924e-02</td>\n",
       "      <td>1.426061e-01</td>\n",
       "      <td>-1.431735e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813426e-01</td>\n",
       "      <td>1.457104e-01</td>\n",
       "      <td>-1.419071e-01</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>8.813003e-01</td>\n",
       "      <td>1.451343e-01</td>\n",
       "      <td>-1.417289e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.771663e+00</td>\n",
       "      <td>9.433045e-01</td>\n",
       "      <td>6.987420e+00</td>\n",
       "      <td>358.210000</td>\n",
       "      <td>1.771737e+00</td>\n",
       "      <td>9.454566e-01</td>\n",
       "      <td>7.010629e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dropoff_datetime  dropoff_latitude  dropoff_longitude    fare_amount  \\\n",
       "count      2.000000e+05      2.000000e+05       2.000000e+05  200000.000000   \n",
       "mean      -1.733351e-15      1.345292e-13      -1.373620e-13      12.651451   \n",
       "std        1.000000e+00      1.000000e+00       1.000000e+00      10.448343   \n",
       "min       -1.705902e+00     -3.835043e+01      -1.036287e+01       0.000000   \n",
       "25%       -8.706775e-01      1.396898e-01      -1.446472e-01       6.500000   \n",
       "50%       -4.335732e-02      1.430782e-01      -1.435428e-01       9.500000   \n",
       "75%        8.813426e-01      1.457104e-01      -1.419071e-01      14.500000   \n",
       "max        1.771663e+00      9.433045e-01       6.987420e+00     358.210000   \n",
       "\n",
       "       pickup_datetime  pickup_latitude  pickup_longitude  \n",
       "count     2.000000e+05     2.000000e+05      2.000000e+05  \n",
       "mean      8.333068e-16    -7.267381e-14      1.308183e-13  \n",
       "std       1.000000e+00     1.000000e+00      1.000000e+00  \n",
       "min      -1.705888e+00    -3.847370e+01     -1.039477e+01  \n",
       "25%      -8.706638e-01     1.394914e-01     -1.441710e-01  \n",
       "50%      -4.336924e-02     1.426061e-01     -1.431735e-01  \n",
       "75%       8.813003e-01     1.451343e-01     -1.417289e-01  \n",
       "max       1.771737e+00     9.454566e-01      7.010629e+00  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[features] = (df_all[features] - df_all[features].mean() ) / df_all[features].std()\n",
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is ready, the following step is to prepare the datasets for the different stages of a typical ML problem: Training, Validating and Testing. For simplicity we are going for a 70/20/10 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows count: Train dataset -> 140168, Eval dataset -> 39536, Test dataset -> 20296\n"
     ]
    }
   ],
   "source": [
    "# Split into train and eval\n",
    "np.random.seed(seed=1984) #makes split reproducible\n",
    "rands = np.random.rand(len(df_all))\n",
    "df_train = df_all[rands < 0.7]\n",
    "df_eval = df_all[ ( (rands >= 0.7) & (rands < 0.9) ) ]\n",
    "df_test = df_all[rands >= 0.9]\n",
    "\n",
    "print('Rows count: Train dataset -> {}, Eval dataset -> {}, Test dataset -> {}'.format(len(df_train), len(df_eval), len(df_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Defining the feature columns\n",
    "A feature column is an object describing how the model should use raw input data from the features dictionary. When you build an Estimator model, you pass it a list of feature columns that describes each of the features you want the model to use. The tf.feature_column module provides many options for representing data to the model, for this example a numeric_column will suffice, but keep in mind that there are other types of [feature columns](https://www.tensorflow.org/guide/feature_columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fucntion creates the Feature columns of the model\n",
    "def make_feature_cols():\n",
    "    input_columns = [tf.feature_column.numeric_column(k) for k in features] \n",
    "    return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Creating the input function(s)\n",
    "Input functions supply data for training, evaluating, and prediction. More precisely, an input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n",
    "* Features - A Python dictionary in which:\n",
    "   * Each key is the name of a feature.\n",
    "   * Each value is an array containing all of that feature's values.\n",
    "* Label - An array containing the values of the label for every example.\n",
    "\n",
    "Note that the way in which the input function is written highly depends on the way our data is stored, their size and how do we like to read this data. For this simple example we loaded the entire dataset using *pandas dataframes* but keep in mind that there are other, more sophisticated ways of loading data, in particular for gargantuan amonuts of it.<br>\n",
    "It is also possible to define several different input functions, e.g., one for training, another for evaluating and a third one for prediction. In this example, we will use a single function with some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(df, numEpochs, predictionMode=False):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = df,\n",
    "        y = None if predictionMode else df[label],\n",
    "        batch_size = 128,#1 if predictionMode else 128,\n",
    "        num_epochs = numEpochs,\n",
    "        shuffle = True,\n",
    "        queue_capacity = 1000,\n",
    "        num_threads = 1\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Instantiation of the Estimator\n",
    "As stated before, the problem at hand is a Regression problem, fortunately there are [several premade estimators](https://www.tensorflow.org/api_docs/python/tf/estimator) for regression problems. Our first Estimator will be the LinearRegressor. To create this particular estimator we only need to provide the feature columns, the [rest of the parameters](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) are optional. We are also setting the output directory, where the model checkpoints and other data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_keep_checkpoint_max': 5, '_evaluation_master': '', '_num_worker_replicas': 1, '_tf_random_seed': None, '_master': '', '_save_summary_steps': 100, '_is_chief': True, '_device_fn': None, '_train_distribute': None, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002D452B44208>, '_service': None, '_num_ps_replicas': 0, '_model_dir': '../outputs/Simple-TF.estimator-example', '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_task_id': 0}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearRegressor(\n",
    "            feature_columns = make_feature_cols(), \n",
    "            model_dir = OUTPUT_BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Using the Estimator\n",
    "The most common operations that are performed by an estimator are:\n",
    "* Training\n",
    "* Evaluate\n",
    "* Predict\n",
    "\n",
    "#### Trainning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../outputs/Simple-TF.estimator-example\\model.ckpt.\n",
      "INFO:tensorflow:loss = 38451.5, step = 1\n",
      "INFO:tensorflow:global_step/sec: 233.273\n",
      "INFO:tensorflow:loss = 26013.86, step = 101 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.889\n",
      "INFO:tensorflow:loss = 23387.113, step = 201 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.009\n",
      "INFO:tensorflow:loss = 17613.441, step = 301 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.628\n",
      "INFO:tensorflow:loss = 12952.629, step = 401 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.083\n",
      "INFO:tensorflow:loss = 14641.863, step = 501 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.259\n",
      "INFO:tensorflow:loss = 14640.592, step = 601 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.863\n",
      "INFO:tensorflow:loss = 16664.504, step = 701 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.627\n",
      "INFO:tensorflow:loss = 9917.133, step = 801 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.889\n",
      "INFO:tensorflow:loss = 11812.608, step = 901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.008\n",
      "INFO:tensorflow:loss = 9267.086, step = 1001 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.057\n",
      "INFO:tensorflow:loss = 10921.857, step = 1101 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.253\n",
      "INFO:tensorflow:loss = 12438.105, step = 1201 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.695\n",
      "INFO:tensorflow:loss = 11939.945, step = 1301 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.111\n",
      "INFO:tensorflow:loss = 13523.691, step = 1401 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.301\n",
      "INFO:tensorflow:loss = 8813.273, step = 1501 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.861\n",
      "INFO:tensorflow:loss = 9286.055, step = 1601 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.893\n",
      "INFO:tensorflow:loss = 9334.692, step = 1701 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.055\n",
      "INFO:tensorflow:loss = 16105.355, step = 1801 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.008\n",
      "INFO:tensorflow:loss = 7215.0273, step = 1901 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.421\n",
      "INFO:tensorflow:loss = 9628.467, step = 2001 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.966\n",
      "INFO:tensorflow:loss = 6901.1104, step = 2101 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.915\n",
      "INFO:tensorflow:loss = 17666.805, step = 2201 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.835\n",
      "INFO:tensorflow:loss = 13396.346, step = 2301 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.263\n",
      "INFO:tensorflow:loss = 27008.762, step = 2401 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.786\n",
      "INFO:tensorflow:loss = 19617.05, step = 2501 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.406\n",
      "INFO:tensorflow:loss = 17401.434, step = 2601 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.988\n",
      "INFO:tensorflow:loss = 10201.002, step = 2701 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.292\n",
      "INFO:tensorflow:loss = 14928.0205, step = 2801 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.176\n",
      "INFO:tensorflow:loss = 13950.685, step = 2901 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.477\n",
      "INFO:tensorflow:loss = 13891.11, step = 3001 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.236\n",
      "INFO:tensorflow:loss = 9264.822, step = 3101 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.008\n",
      "INFO:tensorflow:loss = 8498.763, step = 3201 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.937\n",
      "INFO:tensorflow:loss = 16265.113, step = 3301 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.702\n",
      "INFO:tensorflow:loss = 6592.33, step = 3401 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.264\n",
      "INFO:tensorflow:loss = 6888.5137, step = 3501 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.844\n",
      "INFO:tensorflow:loss = 14609.119, step = 3601 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.984\n",
      "INFO:tensorflow:loss = 23056.133, step = 3701 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.121\n",
      "INFO:tensorflow:loss = 5951.7686, step = 3801 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.684\n",
      "INFO:tensorflow:loss = 17921.572, step = 3901 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.854\n",
      "INFO:tensorflow:loss = 6818.9746, step = 4001 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.688\n",
      "INFO:tensorflow:loss = 37421.062, step = 4101 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.856\n",
      "INFO:tensorflow:loss = 15148.189, step = 4201 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.854\n",
      "INFO:tensorflow:loss = 12673.965, step = 4301 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.327\n",
      "INFO:tensorflow:loss = 8404.297, step = 4401 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.412\n",
      "INFO:tensorflow:loss = 6245.795, step = 4501 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.836\n",
      "INFO:tensorflow:loss = 15879.896, step = 4601 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.258\n",
      "INFO:tensorflow:loss = 7748.749, step = 4701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.821\n",
      "INFO:tensorflow:loss = 12712.938, step = 4801 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.834\n",
      "INFO:tensorflow:loss = 18209.348, step = 4901 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.66\n",
      "INFO:tensorflow:loss = 12705.404, step = 5001 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.636\n",
      "INFO:tensorflow:loss = 17202.133, step = 5101 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.326\n",
      "INFO:tensorflow:loss = 7548.5757, step = 5201 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.135\n",
      "INFO:tensorflow:loss = 15459.541, step = 5301 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.654\n",
      "INFO:tensorflow:loss = 6965.0684, step = 5401 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.708\n",
      "INFO:tensorflow:loss = 43217.53, step = 5501 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.571\n",
      "INFO:tensorflow:loss = 9846.659, step = 5601 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.868\n",
      "INFO:tensorflow:loss = 11009.902, step = 5701 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.542\n",
      "INFO:tensorflow:loss = 10646.547, step = 5801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.37\n",
      "INFO:tensorflow:loss = 19792.547, step = 5901 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.63\n",
      "INFO:tensorflow:loss = 7999.139, step = 6001 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.968\n",
      "INFO:tensorflow:loss = 10182.549, step = 6101 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.261\n",
      "INFO:tensorflow:loss = 17662.566, step = 6201 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.421\n",
      "INFO:tensorflow:loss = 13575.757, step = 6301 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.862\n",
      "INFO:tensorflow:loss = 14882.877, step = 6401 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.308\n",
      "INFO:tensorflow:loss = 14640.435, step = 6501 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.788\n",
      "INFO:tensorflow:loss = 10607.326, step = 6601 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.521\n",
      "INFO:tensorflow:loss = 11666.505, step = 6701 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.006\n",
      "INFO:tensorflow:loss = 15343.814, step = 6801 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.971\n",
      "INFO:tensorflow:loss = 8494.871, step = 6901 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.575\n",
      "INFO:tensorflow:loss = 12600.473, step = 7001 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.89\n",
      "INFO:tensorflow:loss = 12999.398, step = 7101 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.734\n",
      "INFO:tensorflow:loss = 14268.756, step = 7201 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.537\n",
      "INFO:tensorflow:loss = 9340.973, step = 7301 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.696\n",
      "INFO:tensorflow:loss = 25647.992, step = 7401 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.828\n",
      "INFO:tensorflow:loss = 15085.783, step = 7501 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.231\n",
      "INFO:tensorflow:loss = 8445.063, step = 7601 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.633\n",
      "INFO:tensorflow:loss = 12471.638, step = 7701 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.529\n",
      "INFO:tensorflow:loss = 12851.462, step = 7801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.152\n",
      "INFO:tensorflow:loss = 13785.266, step = 7901 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 12900.455, step = 8001 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.154\n",
      "INFO:tensorflow:loss = 8653.774, step = 8101 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.624\n",
      "INFO:tensorflow:loss = 32829.695, step = 8201 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.037\n",
      "INFO:tensorflow:loss = 14086.114, step = 8301 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.079\n",
      "INFO:tensorflow:loss = 13691.841, step = 8401 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.539\n",
      "INFO:tensorflow:loss = 24889.527, step = 8501 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.23\n",
      "INFO:tensorflow:loss = 9968.984, step = 8601 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.055\n",
      "INFO:tensorflow:loss = 9525.364, step = 8701 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.779\n",
      "INFO:tensorflow:loss = 7213.026, step = 8801 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.907\n",
      "INFO:tensorflow:loss = 10762.988, step = 8901 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.331\n",
      "INFO:tensorflow:loss = 10313.678, step = 9001 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.408\n",
      "INFO:tensorflow:loss = 12810.714, step = 9101 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.486\n",
      "INFO:tensorflow:loss = 16096.156, step = 9201 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.426\n",
      "INFO:tensorflow:loss = 13838.799, step = 9301 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.373\n",
      "INFO:tensorflow:loss = 14862.273, step = 9401 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.32\n",
      "INFO:tensorflow:loss = 8758.788, step = 9501 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.079\n",
      "INFO:tensorflow:loss = 9900.195, step = 9601 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.249\n",
      "INFO:tensorflow:loss = 12719.025, step = 9701 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.102\n",
      "INFO:tensorflow:loss = 14991.471, step = 9801 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.989\n",
      "INFO:tensorflow:loss = 15331.891, step = 9901 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.309\n",
      "INFO:tensorflow:loss = 16405.152, step = 10001 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.083\n",
      "INFO:tensorflow:loss = 11262.836, step = 10101 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.121\n",
      "INFO:tensorflow:loss = 23499.145, step = 10201 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.25\n",
      "INFO:tensorflow:loss = 13351.26, step = 10301 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.574\n",
      "INFO:tensorflow:loss = 12877.391, step = 10401 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.693\n",
      "INFO:tensorflow:loss = 14125.389, step = 10501 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.04\n",
      "INFO:tensorflow:loss = 13372.967, step = 10601 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.492\n",
      "INFO:tensorflow:loss = 13138.523, step = 10701 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.408\n",
      "INFO:tensorflow:loss = 9306.07, step = 10801 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.152\n",
      "INFO:tensorflow:loss = 13228.83, step = 10901 (0.346 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10951 into ../outputs/Simple-TF.estimator-example\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18513.688.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x2d452a1f6a0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(OUTPUT_BASE_DIR, ignore_errors = True) # start fresh each time\n",
    "model.train(input_fn = make_input_fn(df_train, numEpochs = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-06-16:21:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../outputs/Simple-TF.estimator-example\\model.ckpt-10951\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-06-16:21:08\n",
      "INFO:tensorflow:Saving dict for global step 10951: average_loss = 108.52657, global_step = 10951, label/mean = 12.739655, loss = 13885.781, prediction/mean = 12.624673\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10951: ../outputs/Simple-TF.estimator-example\\model.ckpt-10951\n",
      "RMSE on validation dataset = 10.417609214782715\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, name, df):\n",
    "    metrics = model.evaluate(input_fn = make_input_fn(df_eval, numEpochs=1))\n",
    "    print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))\n",
    "\n",
    "print_rmse(model, 'validation', df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting\n",
    "\n",
    "Note that this should be normally unlabelled data, and in general a different format is used for this stage (hence another input function should exist, but for sake of simplicity we are going to reuse the validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../outputs/Simple-TF.estimator-example\\model.ckpt-10951\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'predictions': array([12.518064], dtype=float32)}\n",
      "{'predictions': array([12.089642], dtype=float32)}\n",
      "{'predictions': array([12.102652], dtype=float32)}\n",
      "{'predictions': array([12.807324], dtype=float32)}\n",
      "{'predictions': array([12.625249], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict( input_fn = make_input_fn(df_eval, numEpochs=1, predictionMode=True) )\n",
    "for i in range(5):\n",
    "    print(next(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another model?\n",
    "By reviewing the results we can see that the performance of the model is not really great, its pretty bad actually.. \n",
    "This explains why the RMSE was so high, the model essentially predicts the same amount for every trip. Would a more complex model help? Let's try using a deep neural network. <br>\n",
    "The code to do this is quite straightforward as well.\n",
    "In fact, we dont need to redo steps (1) and (2), just define a new premade estimator and use it. lets quickly define a DNNRegressor with 3 hidden layers containing 32, 8 and 2 neurons respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTPUT_BASE_DIR, ignore_errors = True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTPUT_BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "To open tensorboard, C&P the following command on your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"$ tensorboard --logdir {} --host=127.0.0.1\".format(os.path.abspath(OUTPUT_BASE_DIR)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the training then click [here](http://localhost:6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(input_fn = make_input_fn(df_train, numEpochs = 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the results didnt improve really.. however since the objective of this notebook is to show a simple guide to implement a premade estimator we will leave the production of better models for other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
